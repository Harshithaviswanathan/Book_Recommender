{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n0MQro_OoPT",
        "outputId": "f5bb8b60-dc25-4143-e76d-cf2fb67016f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jyhHz8vOung",
        "outputId": "9f85356b-cca2-409b-b67f-1fcaada83dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkR4Xbb_OvUQ",
        "outputId": "ac5d8158-2cea-4535-8d5a-f30f996556ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.75.222.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Hard-coded K-Means class\n",
        "class HardCodedKMeans:\n",
        "    def __init__(self, n_clusters):\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def fit(self, data):\n",
        "        np.random.seed(42)\n",
        "        initial_indices = np.random.choice(data.shape[0], self.n_clusters, replace=False)\n",
        "        self.centroids = data.iloc[initial_indices].values\n",
        "\n",
        "        for _ in range(100):\n",
        "            self.labels = np.array([self._closest_centroid(row) for row in data.values])\n",
        "            new_centroids = np.array([data[self.labels == k].mean(axis=0) for k in range(self.n_clusters)])\n",
        "            if np.all(new_centroids == self.centroids):\n",
        "                break\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "    def _closest_centroid(self, row):\n",
        "        distances = np.linalg.norm(self.centroids - row, axis=1)\n",
        "        return np.argmin(distances)\n",
        "\n",
        "class HardCodedSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        # Sample word lists for 'positive' and 'negative' sentiments\n",
        "        self.positive_words = ['love', 'good', 'excellent', 'happy', 'joy', 'awesome', 'great', 'friend', 'like', 'enjoy']\n",
        "        self.negative_words = ['bad', 'sad', 'terrible', 'hate', 'angry', 'awful', 'poor', 'dislike', 'pain', 'bored']\n",
        "\n",
        "        # Calculate word counts for each sentiment category\n",
        "        self.dict_positive = self._count_words(self.positive_words)\n",
        "        self.dict_negative = self._count_words(self.negative_words)\n",
        "\n",
        "        # Combine all unique words for likelihood calculation\n",
        "        self.unique_words = set(self.positive_words + self.negative_words)\n",
        "\n",
        "        # Prior probabilities (these can be adjusted based on dataset)\n",
        "        self.prob_positive = 0.6\n",
        "        self.prob_negative = 0.4\n",
        "\n",
        "        # Create the likelihood table\n",
        "        self.df_likelihood = self._create_likelihood_table()\n",
        "\n",
        "        # Initialize to store the latest user input\n",
        "        self.user_input = None\n",
        "\n",
        "    def _count_words(self, words):\n",
        "        word_count = {}\n",
        "        for word in words:\n",
        "            if word not in word_count:\n",
        "                word_count[word] = 1\n",
        "            else:\n",
        "                word_count[word] += 1\n",
        "        return word_count\n",
        "\n",
        "    def _create_likelihood_table(self):\n",
        "        likelihood_data = []\n",
        "        for word in self.unique_words:\n",
        "            positive_prob = self.dict_positive.get(word, 0) / len(self.positive_words)\n",
        "            negative_prob = self.dict_negative.get(word, 0) / len(self.negative_words)\n",
        "            likelihood_data.append([word, positive_prob, negative_prob])\n",
        "\n",
        "        # Create a DataFrame\n",
        "        return pd.DataFrame(likelihood_data, columns=['Word', 'P(word|positive)', 'P(word|negative)'])\n",
        "\n",
        "    def set_user_input(self, text):\n",
        "        \"\"\"Store the latest user input for sentiment analysis.\"\"\"\n",
        "        self.user_input = text\n",
        "\n",
        "    def predict_sentiment(self):\n",
        "        \"\"\"Analyze the stored user input for sentiment prediction.\"\"\"\n",
        "        if self.user_input is None:\n",
        "            return \"No input provided.\"\n",
        "\n",
        "        # Calculate initial scores based on prior probabilities\n",
        "        positive_score = self.prob_positive\n",
        "        negative_score = self.prob_negative\n",
        "\n",
        "        # Split stored user input text\n",
        "        user_words = self.user_input.split(\" \")\n",
        "\n",
        "        word_found = False\n",
        "        for keyword in user_words:\n",
        "            for _, row in self.df_likelihood.iterrows():\n",
        "                if keyword == row['Word']:\n",
        "                    word_found = True\n",
        "                    positive_score *= row['P(word|positive)']\n",
        "                    negative_score *= row['P(word|negative)']\n",
        "                    break\n",
        "\n",
        "        if not word_found:\n",
        "            return \"Neutral or Unrecognized sentiment\"\n",
        "\n",
        "        # Determine sentiment based on the final scores\n",
        "        if positive_score > negative_score:\n",
        "            return \"Positive sentiment\"\n",
        "        else:\n",
        "            return \"Negative sentiment\"\n",
        "\n",
        "\n",
        "\n",
        "class HardCodedLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "            # Update weights and bias\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_classified = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_classified)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Decision Tree class\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree_ = DecisionTreeClassifier(max_depth=self.max_depth)\n",
        "        self.tree_.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.tree_.predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.tree_.predict_proba(X)\n",
        "\n",
        "    def plot(self):\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plot_tree(self.tree_, filled=True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Book Recommender System\", layout=\"wide\")\n",
        "\n",
        "st.title('📚 Book Recommender System')\n",
        "st.subheader('Discover your next favorite book!')\n",
        "\n",
        "# Load datasets\n",
        "books = pd.read_csv('/content/drive/MyDrive/data/books.csv')\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/data/ratings.csv')\n",
        "\n",
        "# Limit ratings for performance\n",
        "ratings = ratings.head(10000)\n",
        "\n",
        "# Prepare user-item matrix\n",
        "user_item_matrix = ratings.pivot(index='user_id', columns='book_id', values='rating').fillna(0)\n",
        "\n",
        "# Create book name list for selection\n",
        "book_name_list = books['title'].tolist()\n",
        "\n",
        "# K-Means Clustering for users\n",
        "kmeans = HardCodedKMeans(n_clusters=5)\n",
        "kmeans.fit(user_item_matrix)\n",
        "\n",
        "analyzer = HardCodedSentimentAnalyzer()\n",
        "\n",
        "# Prepare classification data\n",
        "def prepare_classification_data(ratings, books):\n",
        "    merged = pd.merge(ratings, books[['book_id', 'average_rating']], on='book_id')\n",
        "    merged['liked'] = np.where(merged['rating'] >= 4, 1, 0)\n",
        "    features = merged[['user_id', 'book_id', 'average_rating']]\n",
        "    labels = merged['liked']\n",
        "    return features, labels\n",
        "\n",
        "# Train classifiers\n",
        "features, labels = prepare_classification_data(ratings, books)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_rf.fit(X_train, y_train)\n",
        "\n",
        "clf_svm = SVC(probability=True)\n",
        "clf_svm.fit(X_train, y_train)\n",
        "\n",
        "clf_hc_dt = DecisionTree(max_depth=5)\n",
        "clf_hc_dt.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "clf_hc_lr = HardCodedLogisticRegression()\n",
        "clf_hc_lr.fit(X_train[['user_id', 'book_id', 'average_rating']].values, y_train.values)\n",
        "\n",
        "\n",
        "def get_top_rated_books(books, ratings, n=5):\n",
        "    top_books = ratings.groupby('book_id').agg({'rating': 'mean'}).reset_index()\n",
        "    top_books = top_books.merge(books[['book_id', 'title', 'image_url']], on='book_id')\n",
        "    top_books = top_books.sort_values(by='rating', ascending=False).head(n)\n",
        "    return top_books[['title', 'image_url']]\n",
        "\n",
        "# Function to calculate ROC curves\n",
        "def calculate_roc_curves(X_test, y_test, clf_dict):\n",
        "    roc_curves = {}\n",
        "    for name, clf in clf_dict.items():\n",
        "        y_scores = clf.predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_curves[name] = (fpr, tpr, roc_auc)\n",
        "    return roc_curves\n",
        "\n",
        "# Function to plot ROC curves\n",
        "def plot_roc_curves(roc_curves):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, (fpr, tpr, roc_auc) in roc_curves.items():\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve Comparison')\n",
        "    plt.legend(loc='lower right')\n",
        "    st.pyplot(plt)\n",
        "\n",
        "# Function to predict if a user will like a book\n",
        "def predict_user_like(user_id, book_id, model):\n",
        "    if user_id not in features['user_id'].values or book_id not in features['book_id'].values:\n",
        "        return None\n",
        "\n",
        "    average_rating = books.loc[books['book_id'] == book_id, 'average_rating'].values[0]\n",
        "    input_features = np.array([[user_id, book_id, average_rating]])\n",
        "\n",
        "    prediction = model.predict(input_features)\n",
        "    return prediction[0]\n",
        "\n",
        "# Function to get K-Means recommendations for a specific user\n",
        "def get_recommendations_for_user(user_id):\n",
        "    user_index = user_item_matrix.index.get_loc(user_id)\n",
        "    user_cluster = kmeans.labels[user_index]\n",
        "    cluster_users = user_item_matrix.index[kmeans.labels == user_cluster]\n",
        "\n",
        "    cluster_books = ratings[ratings['user_id'].isin(cluster_users)]\n",
        "    top_books = cluster_books.groupby('book_id').size().reset_index(name='counts')\n",
        "    top_books = top_books.nlargest(5, 'counts')\n",
        "\n",
        "    recommended_books = books[books['book_id'].isin(top_books['book_id'])][['title', 'image_url']]\n",
        "\n",
        "    return {\n",
        "        'recommended_books': recommended_books['title'].tolist(),\n",
        "        'image_urls': recommended_books['image_url'].tolist()\n",
        "    }\n",
        "\n",
        "# KNN Recommendations with distance plot\n",
        "def get_knn_recommendations(selected_book):\n",
        "    book_index = books[books['title'] == selected_book].index[0]\n",
        "    selected_features = user_item_matrix.iloc[:, book_index].values.reshape(1, -1)\n",
        "\n",
        "    knn = NearestNeighbors(n_neighbors=5)\n",
        "    knn.fit(user_item_matrix.T)\n",
        "    distances, indices = knn.kneighbors(selected_features)\n",
        "\n",
        "    recommended_books = books.iloc[indices[0]]['title'].tolist()\n",
        "    recommended_images = books.iloc[indices[0]]['image_url'].tolist()\n",
        "\n",
        "    # Plotting KNN distances\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.barh(range(len(distances[0])), distances[0], color='skyblue')\n",
        "    plt.yticks(range(len(distances[0])), recommended_books)\n",
        "    plt.xlabel('Distance')\n",
        "    plt.title('KNN Distances for Selected Book')\n",
        "    st.pyplot(plt)\n",
        "\n",
        "    return recommended_books, recommended_images\n",
        "\n",
        "# Store conversation history\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "def add_to_chat(role, message):\n",
        "    st.session_state.chat_history.append((role, message))\n",
        "\n",
        "# Sidebar for navigation\n",
        "selected_option = st.sidebar.selectbox(\"Choose an option\",\n",
        "    [\"Top Rated Books\",\"Book Recommendations\", \"Recommendations by User ID\", \"Predict Book Preference\", \"ROC Curve Comparison\",\"User Review Sentiment Analysis\"])\n",
        "\n",
        "# Chat interface\n",
        "def display_chat():\n",
        "    for role, message in st.session_state.chat_history:\n",
        "        if role == \"user\":\n",
        "            st.markdown(f\"<div style='text-align: right; color: blue;'>**You:** {message}</div>\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f\"<div style='text-align: left; color: green;'>**Bot:** {message}</div>\", unsafe_allow_html=True)\n",
        "# User Review Sentiment Analysis\n",
        "\n",
        "if selected_option == \"User Review Sentiment Analysis\":\n",
        "    st.header(\"Analyze Your Review Sentiment\")\n",
        "    user_id = st.number_input(\"Enter Your User ID:\", min_value=1, step=1)\n",
        "    selected_book = st.selectbox(\"Select a Book:\", book_name_list)\n",
        "    user_review = st.text_area(\"Write your review here:\")\n",
        "\n",
        "    if st.button(\"Analyze Sentiment\"):\n",
        "        if user_review:\n",
        "            analyzer.set_user_input(user_review)\n",
        "\n",
        "            # Get the prediction\n",
        "            result = analyzer.predict_sentiment()\n",
        "\n",
        "            add_to_chat(\"user\", f\"Review: {user_review}\")\n",
        "            add_to_chat(\"bot\", f\"The sentiment of the review is: **{result}**\")\n",
        "\n",
        "        display_chat()\n",
        "\n",
        "elif selected_option == \"Top Rated Books\":\n",
        "    st.header(\"📚 Top 5 Rated Books\")\n",
        "    top_books = get_top_rated_books(books, ratings, n=5)\n",
        "\n",
        "    for index, row in top_books.iterrows():\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.image(row['image_url'], width=100)\n",
        "        with col2:\n",
        "            st.write(row['title'])\n",
        "\n",
        "elif selected_option == \"Book Recommendations\":\n",
        "    st.header('Get Book Recommendations')\n",
        "    book_name = st.selectbox('Select Book Name', book_name_list)\n",
        "\n",
        "    if st.button('Get Book Recommendations'):\n",
        "        recommendations, images = get_knn_recommendations(book_name)\n",
        "        add_to_chat(\"user\", f\"Get recommendations for '{book_name}'\")\n",
        "        response = f\"Recommendations based on '{book_name}':\"\n",
        "        add_to_chat(\"bot\", response)\n",
        "\n",
        "        for i in range(len(recommendations)):\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                st.image(images[i], width=100)\n",
        "            with col2:\n",
        "                st.write(recommendations[i])\n",
        "        display_chat()\n",
        "\n",
        "elif selected_option == \"Recommendations by User ID\":\n",
        "    st.header('Get Recommendations by User ID')\n",
        "    user_id_input = st.text_input('Enter your User ID:')\n",
        "\n",
        "    if st.button('Get Recommendations'):\n",
        "        try:\n",
        "            user_id = int(user_id_input)\n",
        "            if user_id in user_item_matrix.index:\n",
        "                recommendations = get_recommendations_for_user(user_id)\n",
        "                add_to_chat(\"user\", f\"Get recommendations for User ID {user_id}\")\n",
        "                response = f\"Top 5 recommended books for User ID {user_id}:\"\n",
        "                add_to_chat(\"bot\", response)\n",
        "\n",
        "                for title, img in zip(recommendations['recommended_books'], recommendations['image_urls']):\n",
        "                    col1, col2 = st.columns(2)\n",
        "                    with col1:\n",
        "                        st.image(img, width=100)\n",
        "                    with col2:\n",
        "                        st.write(title)\n",
        "\n",
        "                user_cluster = kmeans.labels[user_item_matrix.index.get_loc(user_id)]\n",
        "                add_to_chat(\"bot\", f\"User ID {user_id} belongs to Cluster {user_cluster + 1}.\")\n",
        "                display_chat()\n",
        "\n",
        "            else:\n",
        "                add_to_chat(\"bot\", \"User ID not found. Please enter a valid User ID.\")\n",
        "                display_chat()\n",
        "        except ValueError:\n",
        "            add_to_chat(\"bot\", \"Please enter a valid integer for User ID.\")\n",
        "            display_chat()\n",
        "\n",
        "elif selected_option == \"Predict Book Preference\":\n",
        "    st.header('Predict Your Book Preference')\n",
        "    selected_book_name = st.selectbox('Select a book to predict preference', book_name_list)\n",
        "    user_id_input_class = st.text_input('Enter your User ID for prediction:')\n",
        "\n",
        "    model_option = st.selectbox('Select a classification model', ['Random Forest', 'SVM', 'Decision Tree', 'Logistic Regression'])\n",
        "\n",
        "    if st.button('Predict if you will like this book'):\n",
        "        try:\n",
        "            user_id = int(user_id_input_class)\n",
        "            book_id = books.loc[books['title'] == selected_book_name, 'book_id'].values[0]\n",
        "            model = {\n",
        "                'Random Forest': clf_rf,\n",
        "                'SVM': clf_svm,\n",
        "                'Decision Tree': clf_hc_dt,\n",
        "                'Logistic Regression': clf_hc_lr\n",
        "            }[model_option]\n",
        "\n",
        "            if user_id in features['user_id'].values and book_id in features['book_id'].values:\n",
        "                prediction = predict_user_like(user_id, book_id, model)\n",
        "                average_rating = books.loc[books['book_id'] == book_id, 'average_rating'].values[0]\n",
        "                input_features = np.array([[user_id, book_id, average_rating]])\n",
        "\n",
        "                if model_option == 'Logistic Regression':\n",
        "                    predicted_class = clf_hc_lr.predict(input_features)[0]  # Prediction is binary, so we can use it directly\n",
        "                    # Ue the predicted_class to form your response\n",
        "                    if predicted_class == 1:\n",
        "                        response = f\"You will likely like '{selected_book_name}'! 📖\"\n",
        "                    else:\n",
        "                        response = f\"You will likely not like '{selected_book_name}'. 😕\"\n",
        "                else:\n",
        "                    predicted_proba = model.predict_proba(input_features)[0][1]\n",
        "\n",
        "                    if prediction == 1:\n",
        "                        response = f\"You will likely like '{selected_book_name}'! Probability: {predicted_proba:.2f} 📖\"\n",
        "                    else:\n",
        "                        response = f\"You will likely not like '{selected_book_name}'. Probability: {predicted_proba:.2f} 😕\"\n",
        "                add_to_chat(\"user\", f\"Predict preference for '{selected_book_name}' using {model_option}\")\n",
        "                add_to_chat(\"bot\", response)\n",
        "\n",
        "                # Plot the Decision Tree if selected\n",
        "                if model_option == 'Decision Tree':\n",
        "                    plt.figure(figsize=(12, 8))\n",
        "                    clf_hc_dt.plot()  # Ensure you call the plot method from your custom class\n",
        "                    st.pyplot(plt)\n",
        "\n",
        "            else:\n",
        "                add_to_chat(\"bot\", \"User ID or Book ID not found. Please check your input.\")\n",
        "\n",
        "            display_chat()\n",
        "\n",
        "        except ValueError:\n",
        "            add_to_chat(\"bot\", \"Please enter a valid integer for User ID.\")\n",
        "            display_chat()\n",
        "        except IndexError:\n",
        "            add_to_chat(\"bot\", \"The selected book does not exist. Please select a different book.\")\n",
        "            display_chat()\n",
        "\n",
        "elif selected_option == \"ROC Curve Comparison\":\n",
        "    st.header('ROC Curve Comparison of Classification Algorithms')\n",
        "\n",
        "    # Create a dictionary of classifiers\n",
        "    classifiers = {\n",
        "        'Random Forest': clf_rf,\n",
        "        'SVM': clf_svm,\n",
        "        'Decision Tree': clf_hc_dt,\n",
        "\n",
        "    }\n",
        "\n",
        "    # Calculate ROC curves\n",
        "    roc_curves = calculate_roc_curves(X_test, y_test, classifiers)\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plot_roc_curves(roc_curves)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vLimuE-OyYX",
        "outputId": "bff6acc5-4988-4bd7-e79c-0d4944f43ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrZBHAUgPG32",
        "outputId": "73801e27-0bdc-4719-e040-fd1fbdab9032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.222.23:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://rude-peaches-fly.loca.lt\n",
            "/content/app.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n",
            "/content/app.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n",
            "/content/app.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n",
            "/content/app.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n",
            "/content/app.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n",
            "/content/app.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}